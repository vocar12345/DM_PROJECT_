{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find pattern where body style and the following: Dealer Region, gender, transmission, engine\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"car_data.csv\")\n",
    "#drop missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, ensure that all columns used for the transaction encoder are of string type\n",
    "data['Dealer_Region'] = data['Dealer_Region'].astype(str)\n",
    "data['Gender'] = data['Gender'].astype(str)\n",
    "data['Transmission'] = data['Transmission'].astype(str)\n",
    "data['Engine'] = data['Engine'].astype(str)\n",
    "\n",
    "# Now let's create a list of transactions where each transaction is a list of strings\n",
    "transactions = data.drop('Body Style', axis=1).astype(str).values.tolist()\n",
    "\n",
    "# TransactionEncoder's fit and transform data\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply the apriori algorithm to get frequent itemsets\n",
    "# Use min_support to find itemsets with a support of more than 0.5 (you can choose a different threshold)\n",
    "frequent_itemsets = apriori(df, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "# Display the rules with a 'Body_Style' in the consequents\n",
    "# Since the consequents will be a frozenset, we will need to convert the body styles to frozenset for the comparison\n",
    "body_styles = data['Body Style'].unique().tolist()\n",
    "body_styles_frozenset = [frozenset([bs]) for bs in body_styles]\n",
    "\n",
    "# Now filter rules that have a body style as consequent\n",
    "rules_with_body_style = rules[rules['consequents'].isin(body_styles_frozenset)]\n",
    "\n",
    "rules_with_body_style"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
